{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obj_train_data', 'obj.data', 'obj.names', 'train.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Définir le chemin du fichier ZIP et le répertoire de destination\n",
    "zip_file_path = '/media/zf31/YOLOCSDtest.zip'\n",
    "extract_to_path = '/media/DOLPHIN_ALEXIS/Analyses_alexis/YOLOCSDtest'\n",
    "\n",
    "# Path to the video file\n",
    "video_path = '/media/DOLPHIN_ALEXIS/2023/Exp_01_Jun_2024_1145_cam1-4.mp4'\n",
    "\n",
    "\n",
    "# Décompresser le fichier ZIP\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "# Lister les fichiers extraits\n",
    "extracted_files = os.listdir(extract_to_path)\n",
    "extracted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15812"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "labels_folder = os.path.join(extract_to_path, 'obj_train_data')\n",
    "\n",
    "\n",
    "def remove_empty_files(path):\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            if os.path.isfile(file_path) and os.path.getsize(file_path) == 0:\n",
    "                os.remove(file_path)\n",
    "\n",
    "# Replace 'your_directory_path' with the path to your directory\n",
    "remove_empty_files(labels_folder) # Remove empty label files\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(labels_folder)\n",
    "\n",
    "# Check if the list is not empty\n",
    "if files:\n",
    "    # Sort the files in ascending order\n",
    "    files.sort(reverse=False)\n",
    "\n",
    "    # Get the label value from the last file in the directory\n",
    "    label_value = int(files[-1].split('.')[0].split(\"_\")[1].zfill(6))\n",
    "    label_value\n",
    "else:\n",
    "    label_value = 0\n",
    "\n",
    "label_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "video_path = '/media/DOLPHIN_ALEXIS/2023/Exp_01_Jun_2024_1145_cam1-4.mp4'\n",
    "# Directory to save the extracted frames\n",
    "output_dir = os.path.join(extract_to_path, 'images')\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Read the first frame\n",
    "success, frame = video.read()\n",
    "frame_count = 0\n",
    "\n",
    "# Loop through the video frames\n",
    "while success and frame_count <= label_value:\n",
    "    # Save the frame as a JPG image\n",
    "    frame_path = os.path.join(output_dir, f'frame_{frame_count:06d}.jpg')\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "\n",
    "    # Read the next frame\n",
    "    success, frame = video.read()\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video file\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# Define the classes\n",
    "classes = ['dolphin', 'fish', 'diver']\n",
    "\n",
    "# Define the data dictionary\n",
    "data_yaml = {\n",
    "    'train': output_dir,\n",
    "    'val': output_dir,\n",
    "    'nc': len(classes),\n",
    "    'names': classes\n",
    "}\n",
    "\n",
    "\n",
    "yaml_path = os.path.join(extract_to_path,'data_yaml.yaml')\n",
    "# Write the data dictionary to the data.yaml file\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/home1/users/zfne/emanuell/Documents/GitHub/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd /users/zfne/emanuell/Documents/GitHub/yolov5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-12 14:02:49.226453: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-12 14:02:49.226492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-12 14:02:49.227549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=yaml_path, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home1/users/zfne/emanuell/Documents/GitHub/yolov5/train.py\", line 848, in <module>\n",
      "    main(opt)\n",
      "  File \"/export/home1/users/zfne/emanuell/Documents/GitHub/yolov5/train.py\", line 591, in main\n",
      "    check_file(opt.data),\n",
      "  File \"/export/home1/users/zfne/emanuell/Documents/GitHub/yolov5/utils/general.py\", line 504, in check_file\n",
      "    assert len(files), f\"File not found: {file}\"  # assert file was found\n",
      "AssertionError: File not found: yaml_path\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "!python train.py --img 640 --batch 16 --epochs 100 --data yaml_path --cfg yolov5s.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'frame_id': 0,\n",
       "  'label': 'diver',\n",
       "  'x_center': 372.675,\n",
       "  'y_center': 125.515,\n",
       "  'width': 184.11,\n",
       "  'height': 109.03},\n",
       " {'frame_id': 1,\n",
       "  'label': 'diver',\n",
       "  'x_center': 373.0,\n",
       "  'y_center': 124.5,\n",
       "  'width': 184.0,\n",
       "  'height': 109.0},\n",
       " {'frame_id': 2,\n",
       "  'label': 'diver',\n",
       "  'x_center': 372.0,\n",
       "  'y_center': 122.5,\n",
       "  'width': 184.0,\n",
       "  'height': 109.0},\n",
       " {'frame_id': 3,\n",
       "  'label': 'diver',\n",
       "  'x_center': 371.0,\n",
       "  'y_center': 120.5,\n",
       "  'width': 184.0,\n",
       "  'height': 109.0},\n",
       " {'frame_id': 4,\n",
       "  'label': 'diver',\n",
       "  'x_center': 370.0,\n",
       "  'y_center': 120.5,\n",
       "  'width': 184.0,\n",
       "  'height': 109.0}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "!python val.py --data /kaggle/working/data_yaml.yaml --weights runs/train/exp/weights/best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations YOLO créées avec succès.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.general import non_max_suppression\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load YOLOv5 model\n",
    "device = torch.device(device)\n",
    "model = DetectMultiBackend('/users/zfne/emanuell/Documents/GitHub/yolov5/runs/train/exp3/weights/last.pt', device=device)\n",
    "model.eval()\n",
    "\n",
    "# Define a function to resize frames to the model's expected size\n",
    "def resize_frame_to_model_size(frame, model_stride=32):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_height, new_width = (height // model_stride) * model_stride, (width // model_stride) * model_stride\n",
    "    resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "    return resized_frame\n",
    "\n",
    "# Define a function to process video frames\n",
    "def process_frame(frame, model):\n",
    "    # Resize the frame to ensure it is compatible with the model\n",
    "    frame = resize_frame_to_model_size(frame)\n",
    "    \n",
    "    # Preprocess the frame for YOLOv5\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.0\n",
    "    img = torch.from_numpy(img).float().to(device).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    # Run YOLOv5 on the frame\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred)[0]\n",
    "    \n",
    "    # Extract bounding boxes and labels\n",
    "    boxes = pred.cpu().numpy()\n",
    "    labels = model.names\n",
    "    \n",
    "    return boxes, labels\n",
    "\n",
    "# Define a function to annotate frames with detected bounding boxes\n",
    "def annotate_frame(frame, boxes, labels):\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        if labels[int(cls)] == 'diver' or labels[int(cls)] == 'dolphin' or labels[int(cls)] == 'fish':\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            # Add label\n",
    "            cv2.putText(frame, f'{labels[int(cls)]} {conf:.2f}', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Load the video file\n",
    "video_path = '/media/DOLPHIN_ALEXIS/2023/Exp_01_Jun_2024_1145_cam1-4.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "output_path = '/media/DOLPHIN_ALEXIS/output_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Check if video loaded successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Process the video frame by frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Ensure frame is in the correct format\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the entire frame\n",
    "    boxes, labels = process_frame(frame_rgb, model)\n",
    "\n",
    "    # Annotate the frame with the detected boxes and labels\n",
    "    annotated_frame = annotate_frame(frame, boxes, labels)\n",
    "\n",
    "    # Write the annotated frame to the output video file\n",
    "    out.write(annotated_frame)\n",
    "    \n",
    "# Release video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"Video processing complete. The output video is saved to /media/DOLPHIN_ALEXIS/output_video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer train et val 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 images moved from train to val directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the paths\n",
    "train_images_dir = '/home/alexis/Desktop/New_caméra/Custom_dataset/train/images'\n",
    "train_labels_dir = '/home/alexis/Desktop/New_caméra/Custom_dataset/train/labels'\n",
    "val_images_dir = '/home/alexis/Desktop/New_caméra/Custom_dataset/val/images'\n",
    "val_labels_dir = '/home/alexis/Desktop/New_caméra/Custom_dataset/val/labels'\n",
    "\n",
    "# Create the val directories if they don't exist\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "# Get the list of image files in the train directory\n",
    "labels_files = os.listdir(train_labels_dir)\n",
    "\n",
    "# Calculate the number of images to move\n",
    "num_images_to_move = int(len(labels_files) * 0.05)\n",
    "\n",
    "# Randomly select the images to move\n",
    "labels_to_move = random.sample(labels_files, num_images_to_move)\n",
    "\n",
    "# Move the selected images and labels to the val directory\n",
    "for label_file in labels_to_move:\n",
    "    # Move the image file\n",
    "    image_file = label_file.replace('.txt', '.jpg')\n",
    "    src_image_path = os.path.join(train_images_dir, image_file)\n",
    "    dest_image_path = os.path.join(val_images_dir, image_file)\n",
    "    shutil.move(src_image_path, dest_image_path)\n",
    "\n",
    "    # Move the corresponding label file\n",
    "    src_label_path = os.path.join(train_labels_dir, label_file)\n",
    "    dest_label_path = os.path.join(val_labels_dir, label_file)\n",
    "    shutil.move(src_label_path, dest_label_path)\n",
    "\n",
    "# Print the number of images moved\n",
    "print(f\"{num_images_to_move} images and labels moved from train to val directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the images without labels\n",
    "for image_file in os.listdir(train_images_dir):\n",
    "    label_file = image_file.replace('.jpg', '.txt')\n",
    "    if label_file not in labels_files:\n",
    "        image_path = os.path.join(train_images_dir, image_file)\n",
    "        os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Define the classes\n",
    "classes = ['dolphin', 'diver', 'fish']\n",
    "\n",
    "# Define the data dictionary\n",
    "data = {\n",
    "    'train': '/home/alexis/Desktop/New_caméra/Custom_dataset/train/images',\n",
    "    'val': '/home/alexis/Desktop/New_caméra/Custom_dataset/val/images',\n",
    "    'nc': len(classes),\n",
    "    'names': classes\n",
    "}\n",
    "\n",
    "# Write the data dictionary to the data.yaml file\n",
    "with open('/home/alexis/Desktop/New_caméra/Custom_dataset/data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
