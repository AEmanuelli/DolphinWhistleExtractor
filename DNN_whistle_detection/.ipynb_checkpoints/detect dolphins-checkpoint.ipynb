{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe1c40fc-faf5-4242-a716-94af723c0d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dauphins détectés aux instants: [68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_dolphins(video_path, threshold= 5.3e7 , fps =30):\n",
    "    # Ouvrir la vidéo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur lors de l'ouverture de la vidéo.\")\n",
    "        return\n",
    "\n",
    "    frames = []\n",
    "    instants_dauphins = []\n",
    "\n",
    "    frame_number = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convertir en niveau de gris pour simplifier l'analyse\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Si nous avons plus de 10 images, supprimer la plus ancienne\n",
    "        if len(frames) > 10:\n",
    "            frames.pop(0)\n",
    "\n",
    "        # Comparer l'image actuelle avec les dix précédentes\n",
    "        for prev_frame in frames:\n",
    "            diff = cv2.absdiff(gray, prev_frame)\n",
    "            diff_sum = np.sum(diff)\n",
    "            \n",
    "            if diff_sum > threshold:\n",
    "                instants_dauphins.append(frame_number//fps)\n",
    "                break\n",
    "\n",
    "        frames.append(gray)\n",
    "        frame_number += 1\n",
    "\n",
    "    cap.release()\n",
    "    return instants_dauphins\n",
    "\n",
    "video_path = \"/home/alexis/Desktop/short1.mp4\"\n",
    "instants = detect_dolphins(video_path)\n",
    "print(\"Dauphins détectés aux instants:\", instants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595985d-65d3-4373-84a6-d5e8a77f6cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043a6fad-8431-40a6-ab49-b2aabbab5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff89fd-5fc4-402d-9054-5c6eca0be8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "video_path = \"/home/alexis/Desktop/short1.mp4\"\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize background frame for background subtraction\n",
    "_, frame = cap.read()\n",
    "gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "# DataFrame to store motion data\n",
    "motion_list = [None, None]\n",
    "time = []\n",
    "df = pd.DataFrame(columns=[\"Start\", \"End\"])\n",
    "while True:\n",
    "    # Read frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit loop if no more frames are available\n",
    "\n",
    "    motion = 0\n",
    "\n",
    "    # Preprocess the frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # Compute the absolute difference between the current frame and background frame\n",
    "    diff_frame = cv2.absdiff(gray_frame, gray)\n",
    "\n",
    "    # Apply thresholding to get the foreground mask\n",
    "    thresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_frame = cv2.dilate(thresh_frame, None, iterations=2)\n",
    "\n",
    "    # Find contours of moving objects\n",
    "    cnts, _ = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in cnts:\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "        motion = 1\n",
    "        # No need to draw rectangles since we are not displaying images\n",
    "\n",
    "    # Append status of motion\n",
    "    motion_list.append(motion)\n",
    "\n",
    "    motion_list = motion_list[-2:]\n",
    "\n",
    "    # Append Start time of motion\n",
    "    if motion_list[-1] == 1 and motion_list[-2] == 0:\n",
    "        time.append(datetime.now())\n",
    "\n",
    "    # Append End time of motion\n",
    "    if motion_list[-1] == 0 and motion_list[-2] == 1:\n",
    "        time.append(datetime.now())\n",
    "\n",
    "    # Break the loop if no more frames are available\n",
    "    if not ret:\n",
    "        if motion == 1:\n",
    "            time.append(datetime.now())\n",
    "        break\n",
    "\n",
    "\n",
    "# Initialize an empty list to collect rows as dictionaries\n",
    "rows_list = []\n",
    "\n",
    "# Loop to process data and fill the list with row dictionaries\n",
    "for i in range(0, len(time), 2):\n",
    "    row_dict = {\"Start\": time[i], \"End\": time[i + 1]}\n",
    "    rows_list.append(row_dict)\n",
    "\n",
    "# After the loop, create a DataFrame from the list of dictionaries\n",
    "df = pd.concat([pd.DataFrame([row]) for row in rows_list], ignore_index=True)\n",
    "\n",
    "# Release video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12309a06-796f-4c45-90f2-ed237d60d9b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
