{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed10dd7f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-22T11:17:19.315592Z",
     "iopub.status.busy": "2024-05-22T11:17:19.313606Z",
     "iopub.status.idle": "2024-05-22T11:17:46.718843Z",
     "shell.execute_reply": "2024-05-22T11:17:46.717314Z"
    },
    "papermill": {
     "duration": 27.414289,
     "end_time": "2024-05-22T11:17:46.721978",
     "exception": false,
     "start_time": "2024-05-22T11:17:19.307689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "git is already the newest version (1:2.25.1-1ubuntu3.11).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\r\n",
      "Initialized empty Git repository in /kaggle/working/Pipeline_extraction/.git/\r\n",
      "/kaggle/working/Pipeline_extraction\n",
      "Updating origin\r\n",
      "remote: Enumerating objects: 9292, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1887/1887), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (932/932), done.\u001b[K\r\n",
      "remote: Total 9292 (delta 973), reused 1824 (delta 922), pack-reused 7405\u001b[K\r\n",
      "Receiving objects: 100% (9292/9292), 614.37 MiB | 41.37 MiB/s, done.\r\n",
      "Resolving deltas: 100% (973/973), done.\r\n",
      "From https://github.com/AEmanuelli/Dolphins\r\n",
      " * [new branch]      main               -> origin/main\r\n",
      " * [new branch]      previous_structure -> origin/previous_structure\r\n",
      " * [new branch]      restructuration    -> origin/restructuration\r\n",
      "From https://github.com/AEmanuelli/Dolphins\r\n",
      " * branch            main       -> FETCH_HEAD\r\n",
      " __init__.py\t  pipeline.ipynb\t\t  process_predictions.py\r\n",
      " main.py\t  predict_and_extract_online.py   utils.py\r\n",
      " maintenance.py   predict_online.py\t\t 'vid'$'\\303\\251''oaudio.py'\r\n"
     ]
    }
   ],
   "source": [
    "# Installer git\n",
    "!apt-get install git\n",
    "\n",
    "# Initialiser un nouveau dépôt git\n",
    "!git init Pipeline_extraction\n",
    "%cd /kaggle/working/Pipeline_extraction\n",
    "\n",
    "# Configurer sparse-checkout\n",
    "!git config core.sparseCheckout true\n",
    "\n",
    "# Ajouter l'URL du dépôt distant\n",
    "!git remote add -f origin https://github.com/AEmanuelli/Dolphins.git\n",
    "\n",
    "# Spécifier le chemin du sous-répertoire à cloner\n",
    "!echo \"DNN_whistle_detection/Predict_and_extract\" > .git/info/sparse-checkout\n",
    "\n",
    "# Tirer les fichiers du sous-répertoire spécifié\n",
    "!git pull origin main\n",
    "\n",
    "# Vérifier que les fichiers ont été clonés\n",
    "!ls DNN_whistle_detection/Predict_and_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db41010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:17:46.755808Z",
     "iopub.status.busy": "2024-05-22T11:17:46.755394Z",
     "iopub.status.idle": "2024-05-22T11:18:26.844693Z",
     "shell.execute_reply": "2024-05-22T11:18:26.843308Z"
    },
    "papermill": {
     "duration": 40.110095,
     "end_time": "2024-05-22T11:18:26.847888",
     "exception": false,
     "start_time": "2024-05-22T11:17:46.737793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\r\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting keras==2.15.0\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: tensorflow==2.15.0 in /opt/conda/lib/python3.10/site-packages (2.15.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.60.0)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\r\n",
      "Collecting decorator<5.0,>=4.0.2 (from moviepy)\r\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.66.1)\r\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\r\n",
      "Collecting proglog<=1.0.0 (from moviepy)\r\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.33.1)\r\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\r\n",
      "  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.42.0)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.5.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15.0) (3.1.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\r\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\r\n",
      "Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\r\n",
      "Building wheels for collected packages: moviepy\r\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110720 sha256=7fd22d3ed1aa55533ccc69528be03f348cf1be8f8e5486d46f8d011b30b2c190\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\r\n",
      "Successfully built moviepy\r\n",
      "Installing collected packages: proglog, keras, imageio_ffmpeg, decorator, moviepy\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.2.1\r\n",
      "    Uninstalling keras-3.2.1:\r\n",
      "      Successfully uninstalled keras-3.2.1\r\n",
      "  Attempting uninstall: decorator\r\n",
      "    Found existing installation: decorator 5.1.1\r\n",
      "    Uninstalling decorator-5.1.1:\r\n",
      "      Successfully uninstalled decorator-5.1.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.9 keras-2.15.0 moviepy-1.0.3 proglog-0.1.10\r\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy keras==2.15.0 tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48a859e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:18:26.888539Z",
     "iopub.status.busy": "2024-05-22T11:18:26.888091Z",
     "iopub.status.idle": "2024-05-22T11:18:26.965117Z",
     "shell.execute_reply": "2024-05-22T11:18:26.963496Z"
    },
    "papermill": {
     "duration": 0.101079,
     "end_time": "2024-05-22T11:18:26.968097",
     "exception": false,
     "start_time": "2024-05-22T11:18:26.867018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 13 files in '/kaggle/working/' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def split_files_into_chunks(directory_path, chunk_size=12, output_directory='output'):\n",
    "    \"\"\"\n",
    "    Splits the list of files in the specified directory into chunks and writes each chunk to a separate text file.\n",
    "\n",
    "    :param directory_path: Path to the directory containing the files.\n",
    "    :param chunk_size: Number of files per chunk.\n",
    "    :param output_directory: Directory to save the output text files.\n",
    "    \"\"\"\n",
    "    # Get the list of files in the directory\n",
    "    file_list = os.listdir(directory_path)\n",
    "    \n",
    "    # Split the list into chunks of specified size\n",
    "    chunks = [file_list[i:i + chunk_size] for i in range(0, len(file_list), chunk_size)]\n",
    "    \n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Create text files for each chunk\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk_file_path = os.path.join(output_directory, f'file_list_{idx + 1}.txt')\n",
    "        with open(chunk_file_path, 'w') as file:\n",
    "            for filename in chunk:\n",
    "                file.write(filename + '\\n')\n",
    "    \n",
    "    print(f\"Created {len(chunks)} files in '{output_directory}' directory.\")\n",
    "\n",
    "# Example usage\n",
    "directory_path = '/kaggle/input/batch01'  # Change this to your directory path\n",
    "output_directory = '/kaggle/working/'  # Change this to your desired output directory\n",
    "\n",
    "split_files_into_chunks(directory_path, chunk_size=12, output_directory=output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993ba778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:18:27.010850Z",
     "iopub.status.busy": "2024-05-22T11:18:27.010401Z",
     "iopub.status.idle": "2024-05-22T11:18:47.057051Z",
     "shell.execute_reply": "2024-05-22T11:18:47.055954Z"
    },
    "papermill": {
     "duration": 20.072282,
     "end_time": "2024-05-22T11:18:47.060001",
     "exception": false,
     "start_time": "2024-05-22T11:18:26.987719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 11:18:33.615390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 11:18:33.615545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 11:18:33.759475: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/working/Pipeline_extraction/DNN_whistle_detection/Predict_and_extract/main.py\", line 46, in <module>\n",
      "    process_predict_extract(args.recordings, args.saving_folder, args.start_time, args.end_time, args.batch_size, args.save, args.save_p, args.model_path, args.max_workers, specific_files = specific_files)\n",
      "  File \"/kaggle/working/Pipeline_extraction/DNN_whistle_detection/Predict_and_extract/predict_and_extract_online.py\", line 101, in process_predict_extract\n",
      "    files = os.listdir(recording_folder_path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/batch03/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "idxs = [11] #idxs = [1,2,3,4,5]\n",
    "for idx in idxs : \n",
    "    command = f\"\"\"\n",
    "    python DNN_whistle_detection/Predict_and_extract/main.py \\\n",
    "        --model_path \"/kaggle/input/cnn_v1_xception/tensorflow2/initial_model/1/model_vgg.h5\" \\\n",
    "        --recordings \"/kaggle/input/batch03/\" \\\n",
    "        --saving_folder \"/kaggle/working/Analyses_alexis/2021_analysed/\" \\\n",
    "        --start_time 0 \\\n",
    "        --batch_size 64 \\\n",
    "        --save False \\\n",
    "        --save_p True \\\n",
    "        --max_workers 8 \\\n",
    "        --specific_files \"/kaggle/working/file_list_{idx}.txt\"\n",
    "    \"\"\"\n",
    "\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802c0cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:18:47.102599Z",
     "iopub.status.busy": "2024-05-22T11:18:47.102124Z",
     "iopub.status.idle": "2024-05-22T11:18:47.111940Z",
     "shell.execute_reply": "2024-05-22T11:18:47.110113Z"
    },
    "papermill": {
     "duration": 0.033719,
     "end_time": "2024-05-22T11:18:47.114450",
     "exception": false,
     "start_time": "2024-05-22T11:18:47.080731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'archive 2021_analysed_archive_chunk13.zip a été créée avec succès.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Chemin vers le dossier à archiver\n",
    "folder_to_archive = \"/kaggle/working/Analyses_alexis/2021_analysed/\"\n",
    "# Chemin et nom de l'archive à créer\n",
    "output_filename = \"2021_analysed_archive_chunk13.zip\"\n",
    "\n",
    "# Créer l'archive zip\n",
    "shutil.make_archive(output_filename.replace('.zip', ''), 'zip', folder_to_archive)\n",
    "\n",
    "# Vérifier si l'archive a été créée\n",
    "if os.path.exists(output_filename):\n",
    "    print(f\"L'archive {output_filename} a été créée avec succès.\")\n",
    "else:\n",
    "    print(\"La création de l'archive a échoué.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f202eb",
   "metadata": {
    "papermill": {
     "duration": 0.01947,
     "end_time": "2024-05-22T11:18:47.155789",
     "exception": false,
     "start_time": "2024-05-22T11:18:47.136319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5036409,
     "sourceId": 8451128,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 38718,
     "sourceId": 46185,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 40717,
     "sourceId": 48683,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 91.454058,
   "end_time": "2024-05-22T11:18:47.699467",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-22T11:17:16.245409",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
