{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-13T16:00:45.704267Z","iopub.status.busy":"2024-06-13T16:00:45.703723Z","iopub.status.idle":"2024-06-13T16:01:12.900822Z","shell.execute_reply":"2024-06-13T16:01:12.899848Z","shell.execute_reply.started":"2024-06-13T16:00:45.704232Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras==2.15.0 in /export/home1/users/zfne/emanuell/Documents/GitHub/Dolphins/.conda/lib/python3.9/site-packages (2.15.0)\n"]},{"name":"stderr","output_type":"stream","text":["2024-06-21 16:30:17.129164: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-06-21 16:30:17.169961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-21 16:30:17.169992: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-21 16:30:17.171160: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-21 16:30:17.179292: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-21 16:30:18.029644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/export/home1/users/zfne/emanuell/Documents/GitHub/Dolphins/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["!pip install keras==2.15.0\n","#Import Os and Basis Libraries\n","import cv2\n","import os\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt \n","import plotly.graph_objects as go\n","#Matplot Images\n","import matplotlib.image as mpimg\n","# Tensflor and Keras Layer and Model and Optimize and Loss\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","from keras.layers import *\n","from tensorflow.keras.losses import BinaryCrossentropy\n","# import tensorflow_hub as hub\n","import optuna\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n","from tensorflow.keras.applications import ResNet50, InceptionV3, Xception, VGG16\n","from tensorflow.keras.layers import Dense\n","import numpy as np\n","#Image Generator DataAugmentation\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","#Early Stopping\n","from tensorflow.keras.callbacks import EarlyStopping\n","# Warnings Remove \n","import warnings \n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T14:24:51.471293Z","iopub.status.busy":"2024-06-12T14:24:51.470680Z","iopub.status.idle":"2024-06-12T14:24:51.818267Z","shell.execute_reply":"2024-06-12T14:24:51.817247Z","shell.execute_reply.started":"2024-06-12T14:24:51.471263Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                            filename   category\n","0  Exp_17_Dec_2019_1345pm-1182.8.jpg  positives\n","1   Exp_05_Dec_2019_1145am-182.8.jpg  positives\n","2  Exp_16_Jan_2020_1245pm-3208.4.jpg  positives\n","3  Exp_25_Nov_2019_0945am-1299.2.jpg  positives\n","4   Exp_01_Jan_2020_1545pm-579.6.jpg  positives\n"]}],"source":["# Directory containing the \"Train\" folder\n","directory = \"/media/DOLPHIN_ALEXIS/Analyses_alexis/Spectrograms_datasets/dataset/_last/tests\"\n","\n","# List of categories (subfolder names)\n","categories = [\"positives\", \"negatives\"]\n","\n","# Initialize lists to store filenames and categories\n","filenames = []\n","category_labels = []\n","\n","# Iterate through the categories\n","for category in categories:\n","    # Path to the current category folder\n","    category_folder = os.path.join(directory, \"train\", category)\n","    # List all filenames in the category folder\n","    category_filenames = os.listdir(category_folder)\n","    # Append filenames and corresponding category labels\n","    filenames.extend(category_filenames)\n","    category_labels.extend([category] * len(category_filenames))\n","\n","# Create DataFrame\n","df = pd.DataFrame({\n","    'filename': filenames,\n","    'category': category_labels\n","})\n","\n","# Display the first few rows of the DataFrame\n","print(df.head())"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T14:32:09.473221Z","iopub.status.busy":"2024-06-12T14:32:09.472383Z","iopub.status.idle":"2024-06-12T14:32:09.818656Z","shell.execute_reply":"2024-06-12T14:32:09.817396Z","shell.execute_reply.started":"2024-06-12T14:32:09.473187Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-21 16:34:10.827469: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-06-21 16:34:10.851300: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-06-21 16:34:11.025424: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-06-21 16:34:11.027106: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-21 16:34:12.078910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"ename":"AttributeError","evalue":"module 'numpy' has no attribute 'typeDict'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m directory\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Data_Dir\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/__init__.py:45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column_lib \u001b[38;5;28;01mas\u001b[39;00m feature_column\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"FeatureColumns: tools for ingesting and representing features.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence_feature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py:143\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m sparse_tensor_lib\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/layers/base.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_tf_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m     18\u001b[0m InputSpec \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mInputSpec\n\u001b[1;32m     20\u001b[0m keras_style_scope \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mkeras_style_scope\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/keras/models.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sequential\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m network_serialization\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale_optimizer \u001b[38;5;28;01mas\u001b[39;00m lso\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m policy\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hdf5_format\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     38\u001b[0m   HDF5_OBJECT_HEADER_LIMIT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64512\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/h5py/__init__.py:46\u001b[0m\n\u001b[1;32m     37\u001b[0m     _warn((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5py is running against HDF5 \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m when it was built against \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis may cause problems\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_version_tuple),\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_built_version_tuple)\n\u001b[1;32m     41\u001b[0m     ))\n\u001b[1;32m     44\u001b[0m _errors\u001b[38;5;241m.\u001b[39msilence_errors()\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_converters \u001b[38;5;28;01mas\u001b[39;00m _register_converters\n\u001b[1;32m     47\u001b[0m _register_converters()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mh5z\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _register_lzf\n","File \u001b[0;32mh5py/h5t.pxd:14\u001b[0m, in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mh5py/h5t.pyx:293\u001b[0m, in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/miniconda3/envs/TrainCNN/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n","\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"]}],"source":["import tensorflow as tf\n","\n","base_dir = directory\n","\n","# Data_Dir\n","data_dir = os.path.join(base_dir, \"train\")\n","val_dir = os.path.join(base_dir, \"validation\")\n","test_dir_path = os.path.join(base_dir, \"test\")\n","\n","# Defining data generator with Data Augmentation\n","data_gen_augmented = ImageDataGenerator(rescale = 1/255., validation_split = 0.2)\n","\n","print('Training Images:')\n","train_ds = data_gen_augmented.flow_from_directory(data_dir,\n","                                                  target_size = (224, 224),\n","                                                              batch_size = 32,\n","                                                              subset = 'training',\n","                                                              class_mode = 'categorical')\n","\n","\n","# Defining Validation_generator without Data Augmentation\n","data_gen = ImageDataGenerator(rescale = 1/255., validation_split = 0.2)\n","\n","print('Unchanged Validation Images:')\n","validation_ds = data_gen.flow_from_directory(val_dir,\n","                                            target_size = (224, 224),\n","                                        batch_size = 32,\n","                                        subset = 'validation',\n","                                        class_mode = 'categorical')\n","\n","\n","# Defining Test_generator without Data Augmentation\n","data_test_gen = ImageDataGenerator(rescale = 1/255.)\n","\n","print('Test Validation Images:')\n","test_ds = data_test_gen.flow_from_directory(test_dir_path,\n","                                            target_size = (224, 224),\n","                                        batch_size = 50,\n","                                            class_mode = 'categorical')\n","\n","\n","\n","\n","\n","# THE FINETUNED MODEL NEEDS RESCALING BUT THE ORIGINAL MODEL DOESN'T NEED RESCALING\n","\n","\n","data_test_gen_nors = ImageDataGenerator(rescale = 1)\n","test_ds_nors = data_test_gen_nors.flow_from_directory(test_dir_path,\n","                                            target_size = (224, 224),\n","                                        batch_size = 50,\n","                                            class_mode = 'categorical')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['model_vgg', 'CNN_Vgg_V2', 'MPFTACC95+', 'model_finetuned_vgg', 'Augmented_dataset']\n"]}],"source":["import sys\n","import os\n","current_dir = os.getcwd()\n","\n","if current_dir.endswith(\"Train_model\"):\n","    os.chdir(\"../..\")\n","    # Get the current directory\n","    current_dir = os.getcwd()\n","\n","\n","# Append the relative path to the sys.path\n","sys.path.append(os.path.join(current_dir, \"DNN_whistle_detection\"))\n","\n","model_folder = os.path.abspath(os.path.join(current_dir, \"DNN_whistle_detection\", \"models\"))\n","\n","model_paths = os.listdir(model_folder)\n","\n","models = [tf.keras.models.load_model(os.path.join(model_folder, model_path)) for model_path in model_paths]\n","\n","model_names = [os.path.splitext(os.path.basename(model_path))[0] for model_path in model_paths]\n","print(model_names)\n","# print(models[-1].evaluate(test_ds))\n","# print(models[-1].evaluate(test_ds_nors))\n"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["99/99 [==============================] - 61s 617ms/step - loss: 1.6105 - accuracy: 0.5062\n","Model: model_vgg\n","Test Loss: 1.6104717254638672\n","Test Accuracy: 0.506223201751709\n","99/99 [==============================] - 25s 253ms/step - loss: 3.8272 - accuracy: 0.5000\n","Model: CNN_Vgg_V2\n","Test Loss: 3.827242374420166\n","Test Accuracy: 0.5\n","99/99 [==============================] - 25s 247ms/step - loss: 0.1219 - accuracy: 0.9727\n","Model: MPFTACC95+\n","Test Loss: 0.1218729093670845\n","Test Accuracy: 0.972658634185791\n","99/99 [==============================] - 24s 243ms/step - loss: 0.0970 - accuracy: 0.9851\n","Model: model_finetuned_vgg\n","Test Loss: 0.09703508019447327\n","Test Accuracy: 0.9851050972938538\n","99/99 [==============================] - 25s 248ms/step - loss: 0.7042 - accuracy: 0.5591\n","Model: Augmented_dataset\n","Test Loss: 0.704227864742279\n","Test Accuracy: 0.5590695738792419\n"]}],"source":["for model_name, model in zip(model_names, models):\n","    test_loss, test_accuracy = model.evaluate(test_ds, verbose=1)\n","    print(f\"Model: {model_name}\")\n","    print(f\"Test Loss: {test_loss}\")\n","    print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","execution_count":169,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 43ms/step\n","[True, True, True, True, False, False, True, True, True, True, True, False, False, True, True, False, True, True, False, True, False, False, False, False, False, True, False, True, False, False, False, True, False, False, False, True, True, False, True, False, True, True, True, False, False, True, True, False, True, False]\n"]}],"source":["# Get the top 50 images from the test dataset\n","top_50_images = test_ds[0][0][:50]\n","\n","# Make predictions on the top 50 images\n","predictions = models[3].predict(top_50_images)\n","\n","# Get the predicted labels\n","predicted_labels = [np.argmax(prediction) for prediction in predictions]\n","predicted_labels_bis = predicted_labels = [(prediction[1] > prediction[0]) for prediction in predictions]\n","print(predicted_labels_bis)\n","# Get the class labels\n","class_labels = train_ds.class_indices\n","true_labels = test_ds[0][1][:50]\n","\n","# Create a subplot with 5 rows and 10 columns\n","fig, axes = plt.subplots(5, 10, figsize=(15, 12))\n","\n","# Flatten the axes array for easier indexing\n","axes = axes.flatten()\n","\n","# Iterate over the images and their predictions\n","for i in range(len(top_50_images)):\n","    # Plot the image\n","    axes[i].imshow(top_50_images[i])\n","    axes[i].axis('off')\n","    \n","    # Set the title with the predicted label and true label\n","    axes[i].set_title(f\"P: {int(predicted_labels[i])}, T: {np.argmax(true_labels[i])}, Pbis : {int(predicted_labels_bis[i])}\")\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","fig.savefig(\"test_predictions.png\")"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[],"source":["from tensorflow.keras.applications.vgg16 import preprocess_input\n","\n","def create_image_batch(images):\n","    image_batch = []\n","    for image in images:\n","        image = cv2.resize(image, (224, 224))\n","        image = np.expand_dims(image, axis=0)\n","        image = preprocess_input(image)\n","        image = image.astype(float) / 255.0\n","        image_batch.append(image)\n","    images = np.vstack(image_batch)\n","    print(f\"Images shape :  {images.shape}\")\n","    return images "]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[],"source":["from Predict_and_extract.utils import process_audio_file\n","import numpy as np\n","\n","test_file_2024_new = \"/media/DOLPHIN_ALEXIS/2023/Exp_01_Apr_2024_0400_channel_1.wav\"\n","test_file_2019 = \"/media/zf31/Dolphins/Sound/Exp_09_Dec_2019_0845am.wav\"\n","test_file_2021 = \"/media/zf31/Dolphins/Sound/2021/Exp_29_Apr_2021_1545pm.wav\"\n","test_file_2023 = \"/media/DOLPHIN_ALEXIS/2023/Exp_02_Feb_2023_1145_channel_1.wav\"\n","\n","test_files = [test_file_2024_new, test_file_2019, test_file_2021, test_file_2023]"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[],"source":["saving_folder = \"./images\"\n","batch_size = 50\n","start_time = 0\n","end_time = None\n","save = False\n","wlen = 2048\n","nfft = 2048\n","sliding_w = 0.4\n","cut_low_frequency = 3\n","cut_high_frequency = 20\n","target_width_px = 903\n","target_height_px = 677"]},{"cell_type":"code","execution_count":175,"metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:25:03.695718Z","iopub.status.idle":"2024-06-12T14:25:03.696027Z","shell.execute_reply":"2024-06-12T14:25:03.695887Z","shell.execute_reply.started":"2024-06-12T14:25:03.695874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing file /media/DOLPHIN_ALEXIS/2023/Exp_01_Apr_2024_0400_channel_1.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n","Processing file /media/zf31/Dolphins/Sound/Exp_09_Dec_2019_0845am.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n","Processing file /media/zf31/Dolphins/Sound/2021/Exp_29_Apr_2021_1545pm.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n","Processing file /media/DOLPHIN_ALEXIS/2023/Exp_02_Feb_2023_1145_channel_1.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n"]}],"source":["for test_file in test_files:\n","    print(f\"Processing file {test_file}\")\n","    images = process_audio_file(test_file, saving_folder, batch_size, start_time, end_time, save, wlen, nfft, sliding_w, cut_low_frequency, cut_high_frequency, target_width_px, target_height_px)\n","    images_batch = create_image_batch(images)\n","    for model_name, model in zip(model_names, models):\n","        print(f\"Predicting with model {model_name}\")\n","        predictions = model.predict(images_batch, verbose = 0)\n","        predicted_labels = [np.argmax(prediction) for prediction in predictions]\n","\n","        fig, axes = plt.subplots(5, 10 , figsize=(15, 12))\n","        # Flatten the axes array for easier indexing\n","        axes = axes.flatten()\n","\n","        for i, (image, predicted_label) in enumerate(zip(images, predicted_labels)):\n","            axes[i].imshow(image)\n","            axes[i].axis('off')\n","            axes[i].set_title(f\"P: {int(predicted_label)}\")\n","        plt.tight_layout()\n","\n","        # Save the figure under the model and file name\n","        plt.savefig(f\"{model_name}_{os.path.basename(test_file)}.png\")\n","        \n","        plt.close()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4911901,"sourceId":8674855,"sourceType":"datasetVersion"},{"sourceId":177978025,"sourceType":"kernelVersion"},{"modelInstanceId":38718,"sourceId":46185,"sourceType":"modelInstanceVersion"},{"modelInstanceId":40717,"sourceId":48683,"sourceType":"modelInstanceVersion"},{"modelInstanceId":38718,"sourceId":48685,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":4}
