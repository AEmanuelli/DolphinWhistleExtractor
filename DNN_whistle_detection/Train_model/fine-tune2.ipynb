{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-13T16:00:45.704267Z","iopub.status.busy":"2024-06-13T16:00:45.703723Z","iopub.status.idle":"2024-06-13T16:01:12.900822Z","shell.execute_reply":"2024-06-13T16:01:12.899848Z","shell.execute_reply.started":"2024-06-13T16:00:45.704232Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras==2.15.0 in /export/home1/users/zfne/emanuell/Documents/GitHub/Dolphins/.conda/lib/python3.9/site-packages (2.15.0)\n"]},{"name":"stderr","output_type":"stream","text":["2024-06-21 16:30:17.129164: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-06-21 16:30:17.169961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-21 16:30:17.169992: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-21 16:30:17.171160: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-21 16:30:17.179292: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-21 16:30:18.029644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/export/home1/users/zfne/emanuell/Documents/GitHub/Dolphins/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["!pip install keras==2.15.0\n","#Import Os and Basis Libraries\n","import cv2\n","import os\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt \n","import plotly.graph_objects as go\n","#Matplot Images\n","import matplotlib.image as mpimg\n","# Tensflor and Keras Layer and Model and Optimize and Loss\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","from keras.layers import *\n","from tensorflow.keras.losses import BinaryCrossentropy\n","# import tensorflow_hub as hub\n","import optuna\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n","from tensorflow.keras.applications import ResNet50, InceptionV3, Xception, VGG16\n","from tensorflow.keras.layers import Dense\n","import numpy as np\n","#Image Generator DataAugmentation\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","#Early Stopping\n","from tensorflow.keras.callbacks import EarlyStopping\n","# Warnings Remove \n","import warnings \n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T14:24:51.471293Z","iopub.status.busy":"2024-06-12T14:24:51.470680Z","iopub.status.idle":"2024-06-12T14:24:51.818267Z","shell.execute_reply":"2024-06-12T14:24:51.817247Z","shell.execute_reply.started":"2024-06-12T14:24:51.471263Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                            filename   category\n","0  Exp_17_Dec_2019_1345pm-1182.8.jpg  positives\n","1   Exp_05_Dec_2019_1145am-182.8.jpg  positives\n","2  Exp_16_Jan_2020_1245pm-3208.4.jpg  positives\n","3  Exp_25_Nov_2019_0945am-1299.2.jpg  positives\n","4   Exp_01_Jan_2020_1545pm-579.6.jpg  positives\n"]}],"source":["# Directory containing the \"Train\" folder\n","directory = \"/media/DOLPHIN_ALEXIS/Analyses_alexis/Spectrograms_datasets/dataset/_last/tests\"\n","\n","# List of categories (subfolder names)\n","categories = [\"positives\", \"negatives\"]\n","\n","# Initialize lists to store filenames and categories\n","filenames = []\n","category_labels = []\n","\n","# Iterate through the categories\n","for category in categories:\n","    # Path to the current category folder\n","    category_folder = os.path.join(directory, \"train\", category)\n","    # List all filenames in the category folder\n","    category_filenames = os.listdir(category_folder)\n","    # Append filenames and corresponding category labels\n","    filenames.extend(category_filenames)\n","    category_labels.extend([category] * len(category_filenames))\n","\n","# Create DataFrame\n","df = pd.DataFrame({\n","    'filename': filenames,\n","    'category': category_labels\n","})\n","\n","# Display the first few rows of the DataFrame\n","print(df.head())"]},{"cell_type":"code","execution_count":166,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T14:32:09.473221Z","iopub.status.busy":"2024-06-12T14:32:09.472383Z","iopub.status.idle":"2024-06-12T14:32:09.818656Z","shell.execute_reply":"2024-06-12T14:32:09.817396Z","shell.execute_reply.started":"2024-06-12T14:32:09.473187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Images:\n","Found 25937 images belonging to 2 classes.\n","Unchanged Validation Images:\n","Found 2129 images belonging to 2 classes.\n","Test Validation Images:\n","Found 4901 images belonging to 2 classes.\n","Found 4901 images belonging to 2 classes.\n"]}],"source":["import tensorflow as tf\n","\n","base_dir = directory\n","\n","# Data_Dir\n","data_dir = os.path.join(base_dir, \"train\")\n","val_dir = os.path.join(base_dir, \"validation\")\n","test_dir_path = os.path.join(base_dir, \"test\")\n","\n","# Defining data generator with Data Augmentation\n","data_gen_augmented = ImageDataGenerator(rescale = 1/255., validation_split = 0.2)\n","\n","print('Training Images:')\n","train_ds = data_gen_augmented.flow_from_directory(data_dir,\n","                                                  target_size = (224, 224),\n","                                                              batch_size = 32,\n","                                                              subset = 'training',\n","                                                              class_mode = 'categorical')\n","\n","\n","# Defining Validation_generator without Data Augmentation\n","data_gen = ImageDataGenerator(rescale = 1/255., validation_split = 0.2)\n","\n","print('Unchanged Validation Images:')\n","validation_ds = data_gen.flow_from_directory(val_dir,\n","                                            target_size = (224, 224),\n","                                        batch_size = 32,\n","                                        subset = 'validation',\n","                                        class_mode = 'categorical')\n","\n","\n","# Defining Test_generator without Data Augmentation\n","data_test_gen = ImageDataGenerator(rescale = 1/255.)\n","\n","print('Test Validation Images:')\n","test_ds = data_test_gen.flow_from_directory(test_dir_path,\n","                                            target_size = (224, 224),\n","                                        batch_size = 50,\n","                                            class_mode = 'categorical')\n","\n","\n","\n","\n","\n","# THE FINETUNED MODEL NEEDS RESCALING BUT THE ORIGINAL MODEL DOESN'T NEED RESCALING\n","\n","\n","data_test_gen_nors = ImageDataGenerator(rescale = 1)\n","test_ds_nors = data_test_gen_nors.flow_from_directory(test_dir_path,\n","                                            target_size = (224, 224),\n","                                        batch_size = 50,\n","                                            class_mode = 'categorical')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-21 16:30:28.483410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8812 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5\n"]},{"name":"stdout","output_type":"stream","text":["['model_vgg', 'CNN_Vgg_V2', 'MPFTACC95+', 'model_finetuned_vgg', 'Augmented_dataset']\n"]}],"source":["import sys\n","import os\n","current_dir = os.getcwd()\n","\n","if current_dir.endswith(\"Train_model\"):\n","    os.chdir(\"../..\")\n","    # Get the current directory\n","    current_dir = os.getcwd()\n","\n","\n","# Append the relative path to the sys.path\n","sys.path.append(os.path.join(current_dir, \"DNN_whistle_detection\"))\n","\n","model_folder = os.path.abspath(os.path.join(current_dir, \"DNN_whistle_detection\", \"models\"))\n","\n","model_paths = os.listdir(model_folder)\n","\n","models = [tf.keras.models.load_model(os.path.join(model_folder, model_path)) for model_path in model_paths]\n","\n","model_names = [os.path.splitext(os.path.basename(model_path))[0] for model_path in model_paths]\n","print(model_names)\n","# print(models[-1].evaluate(test_ds))\n","# print(models[-1].evaluate(test_ds_nors))\n"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["99/99 [==============================] - 61s 617ms/step - loss: 1.6105 - accuracy: 0.5062\n","Model: model_vgg\n","Test Loss: 1.6104717254638672\n","Test Accuracy: 0.506223201751709\n","99/99 [==============================] - 25s 253ms/step - loss: 3.8272 - accuracy: 0.5000\n","Model: CNN_Vgg_V2\n","Test Loss: 3.827242374420166\n","Test Accuracy: 0.5\n","99/99 [==============================] - 25s 247ms/step - loss: 0.1219 - accuracy: 0.9727\n","Model: MPFTACC95+\n","Test Loss: 0.1218729093670845\n","Test Accuracy: 0.972658634185791\n","99/99 [==============================] - 24s 243ms/step - loss: 0.0970 - accuracy: 0.9851\n","Model: model_finetuned_vgg\n","Test Loss: 0.09703508019447327\n","Test Accuracy: 0.9851050972938538\n","99/99 [==============================] - 25s 248ms/step - loss: 0.7042 - accuracy: 0.5591\n","Model: Augmented_dataset\n","Test Loss: 0.704227864742279\n","Test Accuracy: 0.5590695738792419\n"]}],"source":["for model_name, model in zip(model_names, models):\n","    test_loss, test_accuracy = model.evaluate(test_ds, verbose=1)\n","    print(f\"Model: {model_name}\")\n","    print(f\"Test Loss: {test_loss}\")\n","    print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","execution_count":169,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 43ms/step\n","[True, True, True, True, False, False, True, True, True, True, True, False, False, True, True, False, True, True, False, True, False, False, False, False, False, True, False, True, False, False, False, True, False, False, False, True, True, False, True, False, True, True, True, False, False, True, True, False, True, False]\n"]}],"source":["# Get the top 50 images from the test dataset\n","top_50_images = test_ds[0][0][:50]\n","\n","# Make predictions on the top 50 images\n","predictions = models[3].predict(top_50_images)\n","\n","# Get the predicted labels\n","predicted_labels = [np.argmax(prediction) for prediction in predictions]\n","predicted_labels_bis = predicted_labels = [(prediction[1] > prediction[0]) for prediction in predictions]\n","print(predicted_labels_bis)\n","# Get the class labels\n","class_labels = train_ds.class_indices\n","true_labels = test_ds[0][1][:50]\n","\n","# Create a subplot with 5 rows and 10 columns\n","fig, axes = plt.subplots(5, 10, figsize=(15, 12))\n","\n","# Flatten the axes array for easier indexing\n","axes = axes.flatten()\n","\n","# Iterate over the images and their predictions\n","for i in range(len(top_50_images)):\n","    # Plot the image\n","    axes[i].imshow(top_50_images[i])\n","    axes[i].axis('off')\n","    \n","    # Set the title with the predicted label and true label\n","    axes[i].set_title(f\"P: {int(predicted_labels[i])}, T: {np.argmax(true_labels[i])}, Pbis : {int(predicted_labels_bis[i])}\")\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","fig.savefig(\"test_predictions.png\")"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[],"source":["from tensorflow.keras.applications.vgg16 import preprocess_input\n","\n","def create_image_batch(images):\n","    image_batch = []\n","    for image in images:\n","        image = cv2.resize(image, (224, 224))\n","        image = np.expand_dims(image, axis=0)\n","        image = preprocess_input(image)\n","        image = image.astype(float) / 255.0\n","        image_batch.append(image)\n","    images = np.vstack(image_batch)\n","    print(f\"Images shape :  {images.shape}\")\n","    return images "]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[],"source":["from Predict_and_extract.utils import process_audio_file\n","import numpy as np\n","\n","test_file_2024_new = \"/media/DOLPHIN_ALEXIS/2023/Exp_01_Apr_2024_0400_channel_1.wav\"\n","test_file_2019 = \"/media/zf31/Dolphins/Sound/Exp_09_Dec_2019_0845am.wav\"\n","test_file_2021 = \"/media/zf31/Dolphins/Sound/2021/Exp_29_Apr_2021_1545pm.wav\"\n","test_file_2023 = \"/media/DOLPHIN_ALEXIS/2023/Exp_02_Feb_2023_1145_channel_1.wav\"\n","\n","test_files = [test_file_2024_new, test_file_2019, test_file_2021, test_file_2023]"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[],"source":["saving_folder = \"./images\"\n","batch_size = 50\n","start_time = 0\n","end_time = None\n","save = False\n","wlen = 2048\n","nfft = 2048\n","sliding_w = 0.4\n","cut_low_frequency = 3\n","cut_high_frequency = 20\n","target_width_px = 903\n","target_height_px = 677"]},{"cell_type":"code","execution_count":175,"metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:25:03.695718Z","iopub.status.idle":"2024-06-12T14:25:03.696027Z","shell.execute_reply":"2024-06-12T14:25:03.695887Z","shell.execute_reply.started":"2024-06-12T14:25:03.695874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing file /media/DOLPHIN_ALEXIS/2023/Exp_01_Apr_2024_0400_channel_1.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n","Processing file /media/zf31/Dolphins/Sound/Exp_09_Dec_2019_0845am.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n","Processing file /media/zf31/Dolphins/Sound/2021/Exp_29_Apr_2021_1545pm.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n","Processing file /media/DOLPHIN_ALEXIS/2023/Exp_02_Feb_2023_1145_channel_1.wav\n","Images shape :  (50, 224, 224, 3)\n","Predicting with model model_vgg\n","Predicting with model CNN_Vgg_V2\n","Predicting with model MPFTACC95+\n","Predicting with model model_finetuned_vgg\n","Predicting with model Augmented_dataset\n"]}],"source":["for test_file in test_files:\n","    print(f\"Processing file {test_file}\")\n","    images = process_audio_file(test_file, saving_folder, batch_size, start_time, end_time, save, wlen, nfft, sliding_w, cut_low_frequency, cut_high_frequency, target_width_px, target_height_px)\n","    images_batch = create_image_batch(images)\n","    for model_name, model in zip(model_names, models):\n","        print(f\"Predicting with model {model_name}\")\n","        predictions = model.predict(images_batch, verbose = 0)\n","        predicted_labels = [np.argmax(prediction) for prediction in predictions]\n","\n","        fig, axes = plt.subplots(5, 10 , figsize=(15, 12))\n","        # Flatten the axes array for easier indexing\n","        axes = axes.flatten()\n","\n","        for i, (image, predicted_label) in enumerate(zip(images, predicted_labels)):\n","            axes[i].imshow(image)\n","            axes[i].axis('off')\n","            axes[i].set_title(f\"P: {int(predicted_label)}\")\n","        plt.tight_layout()\n","\n","        # Save the figure under the model and file name\n","        plt.savefig(f\"{model_name}_{os.path.basename(test_file)}.png\")\n","        \n","        plt.close()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4911901,"sourceId":8674855,"sourceType":"datasetVersion"},{"sourceId":177978025,"sourceType":"kernelVersion"},{"modelInstanceId":38718,"sourceId":46185,"sourceType":"modelInstanceVersion"},{"modelInstanceId":40717,"sourceId":48683,"sourceType":"modelInstanceVersion"},{"modelInstanceId":38718,"sourceId":48685,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
