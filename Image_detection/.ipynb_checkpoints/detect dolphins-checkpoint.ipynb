{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe1c40fc-faf5-4242-a716-94af723c0d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dauphins détectés aux instants: [68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_dolphins(video_path, threshold= 5.3e7 , fps =30):\n",
    "    # Ouvrir la vidéo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur lors de l'ouverture de la vidéo.\")\n",
    "        return\n",
    "\n",
    "    frames = []\n",
    "    instants_dauphins = []\n",
    "\n",
    "    frame_number = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convertir en niveau de gris pour simplifier l'analyse\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Si nous avons plus de 10 images, supprimer la plus ancienne\n",
    "        if len(frames) > 10:\n",
    "            frames.pop(0)\n",
    "\n",
    "        # Comparer l'image actuelle avec les dix précédentes\n",
    "        for prev_frame in frames:\n",
    "            diff = cv2.absdiff(gray, prev_frame)\n",
    "            diff_sum = np.sum(diff)\n",
    "            \n",
    "            if diff_sum > threshold:\n",
    "                instants_dauphins.append(frame_number//fps)\n",
    "                break\n",
    "\n",
    "        frames.append(gray)\n",
    "        frame_number += 1\n",
    "\n",
    "    cap.release()\n",
    "    return instants_dauphins\n",
    "\n",
    "video_path = \"/home/alexis/Desktop/short1.mp4\"\n",
    "instants = detect_dolphins(video_path)\n",
    "print(\"Dauphins détectés aux instants:\", instants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595985d-65d3-4373-84a6-d5e8a77f6cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043a6fad-8431-40a6-ab49-b2aabbab5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ff89fd-5fc4-402d-9054-5c6eca0be8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Start        End\n",
      "0  47.313933  47.847800\n",
      "1  68.468400  69.102367\n",
      "2  90.457033  96.463033\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "video_path = \"/home/alexis/Desktop/short1.mp4\"\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the frames per second (fps) of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Initialize background frame for background subtraction\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the video\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "# DataFrame to store motion data\n",
    "motion_list = [None, None]\n",
    "motion_times = []\n",
    "rows_list = []  # list to collect dictionaries for creating DataFrame\n",
    "df = pd.DataFrame(columns=[\"Start\", \"End\"])\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # Read frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit loop if no more frames are available\n",
    "\n",
    "    motion = 0\n",
    "\n",
    "    # Preprocess the frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # Compute the absolute difference between the current frame and background frame\n",
    "    diff_frame = cv2.absdiff(gray_frame, gray)\n",
    "\n",
    "    # Apply thresholding to get the foreground mask\n",
    "    thresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_frame = cv2.dilate(thresh_frame, None, iterations=2)\n",
    "\n",
    "    # Find contours of moving objects\n",
    "    cnts, _ = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in cnts:\n",
    "        if cv2.contourArea(contour) < 8000:\n",
    "            continue\n",
    "        motion = 1\n",
    "\n",
    "    # Append status of motion\n",
    "    motion_list.append(motion)\n",
    "    motion_list = motion_list[-2:]\n",
    "\n",
    "    # Append Start time of motion\n",
    "    if motion_list[-1] == 1 and motion_list[-2] == 0:\n",
    "        motion_times.append(frame_count / fps)\n",
    "\n",
    "    # Append End time of motion\n",
    "    if motion_list[-1] == 0 and motion_list[-2] == 1:\n",
    "        motion_times.append(frame_count / fps)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "for i in range(0, len(motion_times), 2):\n",
    "    rows_list.append({\"Start\": motion_times[i], \"End\": motion_times[i + 1]})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "df = pd.concat([pd.DataFrame([row]) for row in rows_list], ignore_index=True)\n",
    "\n",
    "# Release video capture object\n",
    "cap.release()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b7839d-49a6-4ece-b100-94b3fc37d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted CONTOUR_AREA_THRESHOLD: 1500\n",
      "Motion Events: [(89.5, 96.36666666666666)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "def find_single_motion_event(video_path, initial_threshold, fps, duration_threshold=3, increment=100, max_iterations=50):\n",
    "    \"\"\"\n",
    "    Modifies the CONTOUR_AREA_THRESHOLD to find a single motion event.\n",
    "\n",
    "    :param video_path: Path to the video file\n",
    "    :param initial_threshold: Initial contour area threshold\n",
    "    :param fps: Frames per second of the video\n",
    "    :param duration_threshold: Duration in seconds to qualify as motion\n",
    "    :param increment: Value to adjust the threshold by in each iteration\n",
    "    :param max_iterations: Maximum number of iterations to attempt\n",
    "    :return: The adjusted CONTOUR_AREA_THRESHOLD and the motion event times\n",
    "    \"\"\"\n",
    "    CONTOUR_AREA_THRESHOLD = initial_threshold\n",
    "    iteration = 0\n",
    "    motion_events = []\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        motion_list = [None, None]\n",
    "        frame_count = 0\n",
    "        motion_start_frame = None\n",
    "\n",
    "        # Initialize background frame for background subtraction\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to read the video\")\n",
    "            cap.release()\n",
    "            return None\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "            diff_frame = cv2.absdiff(gray_frame, gray)\n",
    "            thresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh_frame = cv2.dilate(thresh_frame, None, iterations=2)\n",
    "            cnts, _ = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            motion = 0\n",
    "            for contour in cnts:\n",
    "                if cv2.contourArea(contour) < CONTOUR_AREA_THRESHOLD:\n",
    "                    continue\n",
    "                motion = 1\n",
    "                break\n",
    "\n",
    "            motion_list.append(motion)\n",
    "            motion_list = motion_list[-2:]\n",
    "\n",
    "            # Record start of motion\n",
    "            if motion_list[-1] == 1 and motion_list[-2] == 0:\n",
    "                motion_start_frame = frame_count\n",
    "\n",
    "            # Record end of motion\n",
    "            if motion_list[-1] == 0 and motion_list[-2] == 1 and motion_start_frame is not None:\n",
    "                duration = (frame_count - motion_start_frame) / fps\n",
    "                if duration >= duration_threshold:\n",
    "                    motion_events.append((motion_start_frame / fps, frame_count / fps))\n",
    "                motion_start_frame = None\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Check if we have exactly one motion event\n",
    "        if len(motion_events) == 1:\n",
    "            # Found exactly one motion event\n",
    "            break\n",
    "        elif len(motion_events) > 1:\n",
    "            # Found too many motion events, increase the threshold\n",
    "            CONTOUR_AREA_THRESHOLD += increment\n",
    "        else:\n",
    "            # No motion events found, decrease the threshold\n",
    "            CONTOUR_AREA_THRESHOLD = max(CONTOUR_AREA_THRESHOLD - increment, 0)\n",
    "\n",
    "        motion_events = []  # Reset the list for the next iteration\n",
    "        iteration += 1\n",
    "\n",
    "    return CONTOUR_AREA_THRESHOLD, motion_events\n",
    "\n",
    "# Set the parameters for the function\n",
    "video_path = \"/home/alexis/Desktop/short1.mp4\"\n",
    "initial_threshold = 1000  # Start with a reasonable threshold\n",
    "fps = 30  # Example FPS, you would get this from the video capture object\n",
    "duration_threshold = 3  # Duration of motion to detect in seconds\n",
    "\n",
    "# Call the function\n",
    "CONTOUR_AREA_THRESHOLD, motion_events = find_single_motion_event(\n",
    "    video_path,\n",
    "    initial_threshold,\n",
    "    fps,\n",
    "    duration_threshold\n",
    ")\n",
    "\n",
    "print(f\"Adjusted CONTOUR_AREA_THRESHOLD: {CONTOUR_AREA_THRESHOLD}\")\n",
    "print(f\"Motion Events: {motion_events}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12309a06-796f-4c45-90f2-ed237d60d9b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
