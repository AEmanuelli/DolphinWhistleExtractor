{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-06T13:31:40.183472Z","iopub.status.busy":"2024-06-06T13:31:40.182841Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 ðŸš€ 2024-6-6 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n","Adding AutoShape... \n"]}],"source":["# Kaggle Notebook: People Detection in Security Camera Footage using YOLOv5 (GPU Support)\n","\n","import torch\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Check if GPU is available\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Using device: {device}')\n","\n","# Load YOLOv5 model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s').to(device)\n","\n","# Define a function to process video frames\n","def process_frame(frame, model):\n","    # Run YOLOv5 on the frame\n","    results = model(frame)\n","\n","    # Extract bounding boxes and labels\n","    boxes = results.xyxy[0].cpu().numpy()\n","    labels = results.names\n","    \n","    return boxes, labels\n","\n","# Define a function to annotate frames with detected bounding boxes\n","def annotate_frame(frame, boxes, labels):\n","    for box in boxes:\n","        x1, y1, x2, y2, conf, cls = box\n","        if labels[int(cls)] == 'person':\n","            # Draw bounding box\n","            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n","            # Add label\n","            cv2.putText(frame, f'{labels[int(cls)]} {conf:.2f}', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","    \n","    return frame\n","\n","# Load the video file\n","video_path = '/kaggle/input/exp-01-jun-2024-1145-cam1-4-mp4/Exp_01_Jun_2024_1145_cam1-4.mp4'\n","cap = cv2.VideoCapture(video_path)\n","\n","# Get video properties\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Define the codec and create VideoWriter object\n","output_path = '/kaggle/working/output_video.mp4'\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n","\n","# Check if video loaded successfully\n","if not cap.isOpened():\n","    print(\"Error opening video stream or file\")\n","\n","# Process the video frame by frame\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    # Split the frame into four quadrants\n","    height, width, _ = frame.shape\n","    half_height, half_width = height // 2, width // 2\n","    \n","    quadrants = [\n","        frame[0:half_height, 0:half_width],\n","        frame[0:half_height, half_width:width],\n","        frame[half_height:height, 0:half_width],\n","        frame[half_height:height, half_width:width]\n","    ]\n","    \n","    # Process each quadrant\n","    for i, quadrant in enumerate(quadrants):\n","        # Ensure quadrant frame is in the correct format\n","        quadrant_rgb = cv2.cvtColor(quadrant, cv2.COLOR_BGR2RGB)\n","        boxes, labels = process_frame(quadrant_rgb, model)\n","        quadrants[i] = annotate_frame(quadrant, boxes, labels)\n","    \n","    # Combine the quadrants back into a single frame\n","    top_row = np.hstack((quadrants[0], quadrants[1]))\n","    bottom_row = np.hstack((quadrants[2], quadrants[3]))\n","    combined_frame = np.vstack((top_row, bottom_row))\n","    \n","    # Write the frame to the output video file\n","    out.write(combined_frame)\n","\n","# Release video capture and writer objects\n","cap.release()\n","out.release()\n","\n","print(\"Video processing complete. The output video is saved to /kaggle/working/output_video.mp4\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import json\n","from pathlib import Path\n","import cv2\n","\n","# Load the labels from the JSON file\n","labels_path = '/home/alexis/Downloads/BELOW_LABELS.json'\n","with open(labels_path) as f:\n","    labels = json.load(f)\n","\n","# Create directories for YOLO format labels\n","Path('/home/alexis/Desktop/YODOL/labels/train').mkdir(parents=True, exist_ok=True)\n","Path('/home/alexis/Desktop/YODOL/labels/val').mkdir(parents=True, exist_ok=True)\n","Path('/home/alexis/Desktop/YODOL/images/train').mkdir(parents=True, exist_ok=True)\n","Path('/home/alexis/Desktop/YODOL/images/val').mkdir(parents=True, exist_ok=True)\n","\n","# Split data into train and val sets (assuming a 80-20 split)\n","image_files = list(labels.keys())\n","split_index = int(0.8 * len(image_files))\n","train_images = image_files[:split_index]\n","val_images = image_files[split_index:]\n","\n","def convert_polyline_to_bbox(points_x, points_y, width, height):\n","    x_min, x_max = min(points_x), max(points_x)\n","    y_min, y_max = min(points_y), max(points_y)\n","    x_center = (x_min + x_max) / 2 / width\n","    y_center = (y_min + y_max) / 2 / height\n","    bbox_width = (x_max - x_min) / width\n","    bbox_height = (y_max - y_min) / height\n","    return f\"0 {x_center} {y_center} {bbox_width} {bbox_height}\"\n","\n","def save_labels(images, split):\n","    for image in images:\n","        img_path = f\"/home/alexis/Downloads/BELOW/{labels[image]['filename']}\"\n","        new_image_path = f\"/home/alexis/Desktop/YODOL/images/{split}/{labels[image]['filename']}\"\n","        if not os.path.exists(img_path):\n","            print(f\"File does not exist: {img_path}\")\n","            continue\n","\n","        try:\n","            img = cv2.imread(img_path)\n","            if img is None:\n","                raise Exception(\"Unable to read image.\")\n","            height, width, _ = img.shape\n","            shutil.copy(img_path, new_image_path )\n","        except Exception as e:\n","            print(f\"Error processing image: {img_path} - {e}\")\n","            continue\n","        \n","        yolo_labels = []\n","        for region in labels[image]['regions']:\n","            points_x = region['shape_attributes']['all_points_x']\n","            points_y = region['shape_attributes']['all_points_y']\n","            yolo_labels.append(convert_polyline_to_bbox(points_x, points_y, width, height))\n","\n","        label_path = f\"/home/alexis/Desktop/YODOL/labels/{split}/{Path(image).stem}.txt\"\n","        with open(label_path, 'w') as f:\n","            f.write(\"\\n\".join(yolo_labels))\n","\n","save_labels(train_images, 'train')\n","save_labels(val_images, 'val')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5162402,"sourceId":8623370,"sourceType":"datasetVersion"},{"modelInstanceId":1199,"sourceId":1418,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
