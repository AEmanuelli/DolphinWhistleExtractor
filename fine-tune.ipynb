{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8272602,"sourceType":"datasetVersion","datasetId":4911901},{"sourceId":177975177,"sourceType":"kernelVersion"},{"sourceId":46185,"sourceType":"modelInstanceVersion","modelInstanceId":38718},{"sourceId":48683,"sourceType":"modelInstanceVersion","modelInstanceId":40717},{"sourceId":48685,"sourceType":"modelInstanceVersion","modelInstanceId":38718},{"sourceType":"kernelVersion","sourceId":177978025}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras==2.15.0\n#Import Os and Basis Libraries\nimport cv2\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport plotly.graph_objects as go\n#Matplot Images\nimport matplotlib.image as mpimg\n# Tensflor and Keras Layer and Model and Optimize and Loss\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import *\nfrom tensorflow.keras.losses import BinaryCrossentropy\n# import tensorflow_hub as hub\nimport optuna\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\nfrom tensorflow.keras.applications import ResNet50, InceptionV3, Xception, VGG16\nfrom tensorflow.keras.layers import Dense\nimport numpy as np\n#Image Generator DataAugmentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\n#Early Stopping\nfrom tensorflow.keras.callbacks import EarlyStopping\n# Warnings Remove \nimport warnings \nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T10:08:59.512297Z","iopub.execute_input":"2024-05-16T10:08:59.512662Z","iopub.status.idle":"2024-05-16T10:09:15.203509Z","shell.execute_reply.started":"2024-05-16T10:08:59.512633Z","shell.execute_reply":"2024-05-16T10:09:15.201969Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting keras==2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryCrossentropy\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# import tensorflow_hub as hub\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.losses'"],"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow.keras.losses'","output_type":"error"}]},{"cell_type":"code","source":"# Directory containing the \"Train\" folder\ndirectory = \"/kaggle/input/whistles-baby-hit-me-up/media/DOLPHIN_ALEXIS/Analyses_alexis/dataset/_last/tests\"\n\n# List of categories (subfolder names)\ncategories = [\"negatives\", \"positives\"]\n\n# Initialize lists to store filenames and categories\nfilenames = []\ncategory_labels = []\n\n# Iterate through the categories\nfor category in categories:\n    # Path to the current category folder\n    category_folder = os.path.join(directory, \"train\", category)\n    # List all filenames in the category folder\n    category_filenames = os.listdir(category_folder)\n    # Append filenames and corresponding category labels\n    filenames.extend(category_filenames)\n    category_labels.extend([category] * len(category_filenames))\n\n# Create DataFrame\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': category_labels\n})\n\n# Display the first few rows of the DataFrame\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:09:15.204257Z","iopub.status.idle":"2024-05-16T10:09:15.204609Z","shell.execute_reply.started":"2024-05-16T10:09:15.204414Z","shell.execute_reply":"2024-05-16T10:09:15.204443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data_Dir\ndata_dir = '/kaggle/input/whistles-baby-hit-me-up/media/DOLPHIN_ALEXIS/Analyses_alexis/dataset/_last/tests/train/'\n\n# Defining data generator with Data Augmentation\ndata_gen_augmented = ImageDataGenerator(rescale = 1/255., validation_split = 0.2)\n\nprint('Augmented training Images:')\ntrain_ds = data_gen_augmented.flow_from_directory(data_dir, \n                                                              target_size = (224, 224), \n                                                              batch_size = 32,\n                                                              subset = 'training',\n                                                              class_mode = 'categorical')\n\n#Testing Augmented Data\n# Defining Validation_generator withour Data Augmentation\ndata_gen = ImageDataGenerator(rescale = 1/255., validation_split = 0.2)\n\nprint('Unchanged Validation Images:')\nvalidation_ds = data_gen.flow_from_directory(data_dir, \n                                        target_size = (224, 224), \n                                        batch_size = 32,\n                                        subset = 'validation',\n                                        class_mode = 'categorical')\n\n#Testing Augmented Data\ntest_dir_path = \"/kaggle/input/whistles-baby-hit-me-up/media/DOLPHIN_ALEXIS/Analyses_alexis/dataset/_last/tests/test\"\n# Defining Validation_generator withour Data Augmentation\ndata_test_gen = ImageDataGenerator(rescale = 1/255.)\n\nprint('Test Validation Images:')\ntest_ds = data_gen.flow_from_directory(test_dir_path, \n                                        target_size = (224, 224), \n                                        batch_size = 32,\n                                        subset = 'validation',\n                                        class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:09:15.206131Z","iopub.status.idle":"2024-05-16T10:09:15.206454Z","shell.execute_reply.started":"2024-05-16T10:09:15.206286Z","shell.execute_reply":"2024-05-16T10:09:15.206298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_paper = tf.keras.models.load_model(\"/kaggle/input/cnn_v1_xception/tensorflow2/initial_model/1/model_vgg.h5\") #tf & keras ==2.15.0\n\n#Early_Stopping\nearly_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=5, \n    restore_best_weights=True,\n)\n\n#Fitting Model\n\"\"\"history = model_paper.fit(train_ds,\n                        epochs= 15,\n                        steps_per_epoch = len(train_ds),\n                        validation_data = validation_ds,\n                        validation_steps = len(validation_ds),\n                        callbacks = early_stopping)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:09:15.207827Z","iopub.status.idle":"2024-05-16T10:09:15.208160Z","shell.execute_reply.started":"2024-05-16T10:09:15.207996Z","shell.execute_reply":"2024-05-16T10:09:15.208009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_paper.save(\"kaggle/working/model_finetuned_vgg.h5\")\nmodel_paper= tf.keras.models.load_model(\"/kaggle/input/cnn_v1_xception/tensorflow2/model_initial_finetuned_95acc/1/model_finetuned_vgg.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:09:15.209127Z","iopub.status.idle":"2024-05-16T10:09:15.209474Z","shell.execute_reply.started":"2024-05-16T10:09:15.209292Z","shell.execute_reply":"2024-05-16T10:09:15.209305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/')\nfrom utility_script import *\n\n#********************* MAIN\nmodel_path = \"/kaggle/input/cnn_v1_xception/tensorflow2/initial_model/1/model_vgg.h5\"\nimages_path = \"/kaggle/input/whistles-baby-hit-me-up/media/DOLPHIN_ALEXIS/Analyses_alexis/dataset/_last/tests/train/negatives\"\npositive_dir = \"/kaggle/working/tests/train/negatives/train/negatives/positive\"\nnegative_dir = \"/kaggle/working/tests/train/negatives/train/negatives/negative\"\nif not os.path.exists(positive_dir):\n    os.makedirs(positive_dir)\nif not os.path.exists(negative_dir):\n    os.makedirs(negative_dir)\ncsv_path = \"/kaggle/working/tests/whistles.csv\"\n\n# the model\nmodel = tf.keras.models.load_model(model_path)\n\n# paths of all files\nall_files_path = [f for f in os.listdir(images_path) if isfile(join(images_path, f))]\n\n# lists to store data\nrecord_names = []\npositive_initial = []\npositive_finish = []\nclass_1_scores = []\n\n# all predictions results\npredictions = []\n\n# reading file paths 1 by 1\nfor file_path in all_files_path:\n    \n    # prediction on the given image\n    prediction = predict(model, images_path, file_path)\n    prediction_1= predict(model_paper, images_path, file_path)\n    predictions.append([file_path, prediction, prediction_1])\n    \n    # if the class 1 has higher confidence than class 0\n    if (prediction[0][1] > prediction[0][0]):\n        \n        # carry the positive image to its folder.\n        copy_file(images_path, file_path, positive_dir)\n        \n        # storing the positive images confidences\n        class_1_scores.append((prediction[0][1],prediction_1[0][1]))\n        \n        # preparing arrays for the csv\n        record_names, positive_initial, positive_finish = prepare_csv_data(file_path,\n                                                                           record_names,\n                                                                           positive_initial,\n                                                                           positive_finish)\n    else:\n        pass\n        # carry the negative image to its folder.\n        #copy_file(images_path, file_path, negative_dir)\n        \n    \n\n#saving the csv\nsave_csv(record_names, positive_initial, positive_finish, class_1_scores, csv_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:09:15.211325Z","iopub.status.idle":"2024-05-16T10:09:15.211818Z","shell.execute_reply.started":"2024-05-16T10:09:15.211583Z","shell.execute_reply":"2024-05-16T10:09:15.211603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}