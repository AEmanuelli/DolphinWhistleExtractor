{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 37 files in '/Users/apple/Desktop/2018/25 y 26 nov show sotto/Hidrofono 13 del lado del parto_analyse' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def split_files_into_chunks(directory_path, chunk_size=12, output_directory='output'):\n",
    "    \"\"\"\n",
    "    Splits the list of files in the specified directory into chunks and writes each chunk to a separate text file.\n",
    "\n",
    "    :param directory_path: Path to the directory containing the files.\n",
    "    :param chunk_size: Number of files per chunk.\n",
    "    :param output_directory: Directory to save the output text files.\n",
    "    \"\"\"\n",
    "    # Get the list of files in the directory\n",
    "    file_list = [os.path.join(directory_path, file) for file in os.listdir(directory_path)]\n",
    "    \n",
    "    # Split the list into chunks of specified size\n",
    "    chunks = [file_list[i:i + chunk_size] for i in range(0, len(file_list), chunk_size)]\n",
    "    \n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Create text files for each chunk\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk_file_path = os.path.join(output_directory, f'file_list_{idx + 1}.txt')\n",
    "        with open(chunk_file_path, 'w') as file:\n",
    "            for filename in chunk:\n",
    "                file.write(filename + '\\n')\n",
    "    \n",
    "    print(f\"Created {len(chunks)} files in '{output_directory}' directory.\")\n",
    "\n",
    "# Example usage\n",
    "directory_path = '/Users/apple/Desktop/2018/25 y 26 nov show sotto/Hidrofono 13 del lado del parto'  # Change this to your directory path\n",
    "output_directory = '/Users/apple/Desktop/2018/25 y 26 nov show sotto/Hidrofono 13 del lado del parto_analyse'  # Change this to your desired output directory\n",
    "\n",
    "split_files_into_chunks(directory_path, chunk_size=12, output_directory=output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06 19:59:09.591783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/apple/Documents/GitHub/Dolphins/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Files that are not going to be processed right now :   0%|\u001b[32m \u001b[0m| 0/3 [00:00<?, ?it/s\u001b[0mProcessing: extrait_7.8min_18.5min\n",
      "Processing: extrait_21min_30min\n",
      "Processing: extrait_40min_47min\n",
      "\n",
      "Batches for None:   0%|\u001b[34m                                  \u001b[0m| 0/17 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "\n",
      "Batches for None:   0%|\u001b[34m                                  \u001b[0m| 0/22 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches for None:   0%|\u001b[34m                                  \u001b[0m| 0/26 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\u001b[A^C\n",
      "Files that are not going to be processed right now :   0%|\u001b[32m \u001b[0m| 0/3 [00:02<?, ?it/s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install moviepy\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "!python3 main.py \\\n",
    "    --model_path \"/Users/apple/Downloads/model_finetuned_vgg (1).h5\" \\\n",
    "    --recordings \"/Users/apple/Desktop/Recordings Patagonia/underwater_extracts/5_11\" \\\n",
    "    --saving_folder \"/Users/apple/Desktop/Test_different_window\" \\\n",
    "    --start_time 0 \\\n",
    "    --batch_size 64 \\\n",
    "    --save False \\\n",
    "    --save_p True \\\n",
    "    --max_workers 8 \\\n",
    "    --CLF 3 \\\n",
    "    --CHF 20 \\\n",
    "    --image_norm False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py \\\n",
    "    --model_path \"/users/zfne/emanuell/Documents/GitHub/Dolphins/DNN_whistle_detection/models/model_vgg.h5\" \\\n",
    "    --recordings \"/media/DOLPHIN_ALEXIS/2023/\" \\\n",
    "    --saving_folder \"/media/DOLPHIN_ALEXIS/Analyses_alexis/2023_analysed/\" \\\n",
    "    --start_time 0 \\\n",
    "    --batch_size 64 \\\n",
    "    --save False \\\n",
    "    --save_p True \\\n",
    "    --max_workers 8 \\\n",
    "    --specific_files \"/media/DOLPHIN_ALEXIS/chunks/file_list_3.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py \\\n",
    "    --model_path \"/users/zfne/emanuell/Documents/GitHub/Dolphins/DNN_whistle_detection/models/model_vgg.h5\" \\\n",
    "    --recordings \"/media/DOLPHIN_ALEXIS/2023/\" \\\n",
    "    --saving_folder \"/media/DOLPHIN_ALEXIS/Analyses_alexis/2023_analysed/\" \\\n",
    "    --start_time 0 \\\n",
    "    --batch_size 64 \\\n",
    "    --save False \\\n",
    "    --save_p True \\\n",
    "    --max_workers 8 \\\n",
    "    --specific_files \"/media/DOLPHIN_ALEXIS/chunks/file_list_4.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py \\\n",
    "    --model_path \"/users/zfne/emanuell/Documents/GitHub/Dolphins/DNN_whistle_detection/models/model_vgg.h5\" \\\n",
    "    --recordings \"/media/DOLPHIN_ALEXIS/2023/\" \\\n",
    "    --saving_folder \"/media/DOLPHIN_ALEXIS/Analyses_alexis/2023_analysed/\" \\\n",
    "    --start_time 0 \\\n",
    "    --batch_size 64 \\\n",
    "    --save False \\\n",
    "    --save_p True \\\n",
    "    --max_workers 8 \\\n",
    "    --specific_files \"/media/DOLPHIN_ALEXIS/chunks/file_list_5.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
